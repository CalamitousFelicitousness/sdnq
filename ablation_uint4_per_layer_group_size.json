{
  "text_encoder": {
    "weights_dtype": "uint4",
    "group_size": 32,
    "modules_to_not_convert": [
      "t_embedder",
      "self_attn.q_proj", "self_attn.k_proj", "self_attn.v_proj", "self_attn.o_proj"
    ],
    "modules_group_size_dict": {
      "64": [
        "layers.0.mlp.gate_proj.weight",
        "layers.0.self_attn.o_proj.weight",
        "layers.0.self_attn.q_proj.weight",
        "layers.1.mlp.gate_proj.weight",
        "layers.1.self_attn.o_proj.weight",
        "layers.1.self_attn.q_proj.weight",
        "layers.10.self_attn.q_proj.weight",
        "layers.11.self_attn.q_proj.weight",
        "layers.12.self_attn.q_proj.weight",
        "layers.13.self_attn.o_proj.weight",
        "layers.13.self_attn.q_proj.weight",
        "layers.14.self_attn.q_proj.weight",
        "layers.15.self_attn.q_proj.weight",
        "layers.16.self_attn.q_proj.weight",
        "layers.17.self_attn.q_proj.weight",
        "layers.18.self_attn.o_proj.weight",
        "layers.18.self_attn.q_proj.weight",
        "layers.19.self_attn.q_proj.weight",
        "layers.2.mlp.gate_proj.weight",
        "layers.2.self_attn.o_proj.weight",
        "layers.2.self_attn.q_proj.weight",
        "layers.20.self_attn.o_proj.weight",
        "layers.20.self_attn.q_proj.weight",
        "layers.21.self_attn.o_proj.weight",
        "layers.21.self_attn.q_proj.weight",
        "layers.22.self_attn.q_proj.weight",
        "layers.23.self_attn.q_proj.weight",
        "layers.24.self_attn.o_proj.weight",
        "layers.24.self_attn.q_proj.weight",
        "layers.25.self_attn.q_proj.weight",
        "layers.26.self_attn.q_proj.weight",
        "layers.27.self_attn.q_proj.weight",
        "layers.28.self_attn.q_proj.weight",
        "layers.29.self_attn.q_proj.weight",
        "layers.3.mlp.gate_proj.weight",
        "layers.3.self_attn.o_proj.weight",
        "layers.3.self_attn.q_proj.weight",
        "layers.30.self_attn.q_proj.weight",
        "layers.31.self_attn.q_proj.weight",
        "layers.32.self_attn.q_proj.weight",
        "layers.33.self_attn.q_proj.weight",
        "layers.34.self_attn.q_proj.weight",
        "layers.35.self_attn.q_proj.weight",
        "layers.4.mlp.gate_proj.weight",
        "layers.4.self_attn.o_proj.weight",
        "layers.4.self_attn.q_proj.weight",
        "layers.5.mlp.gate_proj.weight",
        "layers.5.self_attn.o_proj.weight",
        "layers.5.self_attn.q_proj.weight",
        "layers.6.mlp.gate_proj.weight",
        "layers.6.self_attn.q_proj.weight",
        "layers.7.mlp.gate_proj.weight",
        "layers.7.self_attn.o_proj.weight",
        "layers.7.self_attn.q_proj.weight",
        "layers.8.self_attn.o_proj.weight",
        "layers.8.self_attn.q_proj.weight",
        "layers.9.mlp.gate_proj.weight",
        "layers.9.self_attn.o_proj.weight",
        "layers.9.self_attn.q_proj.weight"
      ],
      "128": [
        "layers.2.mlp.down_proj.weight"
      ]
    }
  },
  "transformer": {
    "weights_dtype": "uint4",
    "group_size": 64,
    "modules_to_not_convert": [
      "t_embedder", "cap_embedder", "siglip_embedder",
      "all_x_embedder", "all_final_layer", "adaLN_modulation",
      "attention.to_q", "attention.to_k", "attention.to_v", "attention.to_out"
    ],
    "modules_group_size_dict": {
      "-1": [
        "all_x_embedder.2-1.weight",
        "layers.25.adaLN_modulation.0.weight",
        "layers.28.adaLN_modulation.0.weight"
      ],
      "32": [
        "all_final_layer.2-1.adaLN_modulation.1.weight",
        "layers.10.adaLN_modulation.0.weight",
        "layers.10.attention.to_v.weight",
        "layers.10.feed_forward.w3.weight",
        "layers.11.adaLN_modulation.0.weight",
        "layers.11.attention.to_v.weight",
        "layers.11.feed_forward.w3.weight",
        "layers.12.adaLN_modulation.0.weight",
        "layers.12.attention.to_v.weight",
        "layers.12.feed_forward.w3.weight",
        "layers.13.adaLN_modulation.0.weight",
        "layers.13.attention.to_v.weight",
        "layers.13.feed_forward.w3.weight",
        "layers.14.attention.to_v.weight",
        "layers.14.feed_forward.w3.weight",
        "layers.15.attention.to_v.weight",
        "layers.15.feed_forward.w3.weight",
        "layers.16.attention.to_v.weight",
        "layers.16.feed_forward.w3.weight",
        "layers.17.attention.to_v.weight",
        "layers.17.feed_forward.w3.weight",
        "layers.18.attention.to_v.weight",
        "layers.18.feed_forward.w3.weight",
        "layers.19.attention.to_v.weight",
        "layers.19.feed_forward.w3.weight",
        "layers.2.adaLN_modulation.0.weight",
        "layers.20.attention.to_v.weight",
        "layers.20.feed_forward.w3.weight",
        "layers.21.adaLN_modulation.0.weight",
        "layers.21.attention.to_v.weight",
        "layers.21.feed_forward.w3.weight",
        "layers.22.adaLN_modulation.0.weight",
        "layers.22.attention.to_v.weight",
        "layers.22.feed_forward.w1.weight",
        "layers.22.feed_forward.w3.weight",
        "layers.23.adaLN_modulation.0.weight",
        "layers.23.attention.to_v.weight",
        "layers.23.feed_forward.w1.weight",
        "layers.23.feed_forward.w2.weight",
        "layers.23.feed_forward.w3.weight",
        "layers.24.adaLN_modulation.0.weight",
        "layers.24.attention.to_v.weight",
        "layers.24.feed_forward.w1.weight",
        "layers.24.feed_forward.w2.weight",
        "layers.24.feed_forward.w3.weight",
        "layers.25.attention.to_v.weight",
        "layers.25.feed_forward.w2.weight",
        "layers.25.feed_forward.w3.weight",
        "layers.26.adaLN_modulation.0.weight",
        "layers.26.attention.to_q.weight",
        "layers.26.attention.to_v.weight",
        "layers.26.feed_forward.w2.weight",
        "layers.26.feed_forward.w3.weight",
        "layers.27.attention.to_q.weight",
        "layers.27.attention.to_v.weight",
        "layers.27.feed_forward.w1.weight",
        "layers.27.feed_forward.w2.weight",
        "layers.27.feed_forward.w3.weight",
        "layers.28.attention.to_k.weight",
        "layers.28.attention.to_q.weight",
        "layers.28.attention.to_v.weight",
        "layers.28.feed_forward.w1.weight",
        "layers.28.feed_forward.w3.weight",
        "layers.29.adaLN_modulation.0.weight",
        "layers.29.attention.to_v.weight",
        "layers.29.feed_forward.w1.weight",
        "layers.29.feed_forward.w3.weight",
        "layers.3.adaLN_modulation.0.weight",
        "layers.4.adaLN_modulation.0.weight",
        "layers.5.adaLN_modulation.0.weight",
        "layers.6.adaLN_modulation.0.weight",
        "layers.6.attention.to_v.weight",
        "layers.7.adaLN_modulation.0.weight",
        "layers.8.adaLN_modulation.0.weight",
        "layers.8.attention.to_v.weight",
        "layers.9.adaLN_modulation.0.weight",
        "layers.9.attention.to_v.weight",
        "layers.9.feed_forward.w3.weight",
        "noise_refiner.0.adaLN_modulation.0.weight",
        "noise_refiner.1.adaLN_modulation.0.weight"
      ],
      "96": [
        "context_refiner.0.attention.to_k.weight",
        "context_refiner.0.attention.to_q.weight",
        "layers.13.attention.to_out.0.weight",
        "layers.16.attention.to_out.0.weight",
        "layers.19.attention.to_out.0.weight",
        "layers.2.attention.to_q.weight",
        "layers.2.attention.to_v.weight",
        "layers.20.attention.to_out.0.weight",
        "layers.21.attention.to_out.0.weight",
        "layers.29.attention.to_out.0.weight",
        "layers.3.attention.to_k.weight",
        "layers.3.attention.to_q.weight",
        "layers.4.attention.to_k.weight",
        "layers.5.attention.to_k.weight",
        "layers.5.attention.to_q.weight"
      ],
      "128": [
        "all_final_layer.2-1.linear.weight",
        "layers.0.attention.to_k.weight",
        "layers.0.attention.to_q.weight",
        "layers.0.attention.to_v.weight",
        "layers.0.feed_forward.w2.weight",
        "layers.1.attention.to_k.weight",
        "layers.1.attention.to_q.weight",
        "layers.1.attention.to_v.weight",
        "layers.1.feed_forward.w2.weight",
        "layers.10.attention.to_out.0.weight",
        "layers.10.feed_forward.w2.weight",
        "layers.11.attention.to_out.0.weight",
        "layers.12.attention.to_out.0.weight",
        "layers.14.attention.to_out.0.weight",
        "layers.15.attention.to_out.0.weight",
        "layers.17.attention.to_out.0.weight",
        "layers.18.attention.to_out.0.weight",
        "layers.2.feed_forward.w2.weight",
        "layers.27.adaLN_modulation.0.weight",
        "layers.3.attention.to_out.0.weight",
        "layers.3.attention.to_v.weight",
        "layers.3.feed_forward.w2.weight",
        "layers.4.attention.to_out.0.weight",
        "layers.4.feed_forward.w2.weight",
        "layers.5.attention.to_out.0.weight",
        "layers.5.feed_forward.w2.weight",
        "layers.6.attention.to_out.0.weight",
        "layers.6.feed_forward.w2.weight",
        "layers.7.attention.to_out.0.weight",
        "layers.7.feed_forward.w2.weight",
        "layers.8.attention.to_out.0.weight",
        "layers.8.feed_forward.w2.weight",
        "layers.9.attention.to_out.0.weight",
        "layers.9.feed_forward.w2.weight",
        "noise_refiner.0.attention.to_k.weight",
        "noise_refiner.0.attention.to_out.0.weight",
        "noise_refiner.0.attention.to_q.weight",
        "noise_refiner.0.attention.to_v.weight",
        "noise_refiner.0.feed_forward.w1.weight",
        "noise_refiner.0.feed_forward.w2.weight",
        "noise_refiner.0.feed_forward.w3.weight",
        "noise_refiner.1.attention.to_k.weight",
        "noise_refiner.1.attention.to_out.0.weight",
        "noise_refiner.1.attention.to_q.weight",
        "noise_refiner.1.attention.to_v.weight",
        "noise_refiner.1.feed_forward.w1.weight",
        "noise_refiner.1.feed_forward.w2.weight",
        "noise_refiner.1.feed_forward.w3.weight",
        "t_embedder.mlp.0.weight",
        "t_embedder.mlp.2.weight"
      ]
    }
  }
}
