{
  "text_encoder": {
    "weights_dtype": "uint4",
    "group_size": 32,
    "modules_to_not_convert": [
      "t_embedder",
      "self_attn.q_proj", "self_attn.k_proj", "self_attn.v_proj", "self_attn.o_proj"
    ],
    "modules_svd_dict": {
      "32": [
        "layers.0.mlp.gate_proj.weight",
        "layers.0.self_attn.o_proj.weight",
        "layers.0.self_attn.q_proj.weight",
        "layers.1.mlp.gate_proj.weight",
        "layers.1.self_attn.o_proj.weight",
        "layers.1.self_attn.q_proj.weight",
        "layers.10.self_attn.q_proj.weight",
        "layers.11.self_attn.q_proj.weight",
        "layers.12.self_attn.q_proj.weight",
        "layers.13.self_attn.o_proj.weight",
        "layers.13.self_attn.q_proj.weight",
        "layers.14.self_attn.q_proj.weight",
        "layers.15.self_attn.q_proj.weight",
        "layers.16.self_attn.q_proj.weight",
        "layers.17.self_attn.q_proj.weight",
        "layers.18.self_attn.o_proj.weight",
        "layers.18.self_attn.q_proj.weight",
        "layers.19.self_attn.q_proj.weight",
        "layers.2.mlp.gate_proj.weight",
        "layers.2.self_attn.o_proj.weight",
        "layers.2.self_attn.q_proj.weight",
        "layers.20.self_attn.o_proj.weight",
        "layers.20.self_attn.q_proj.weight",
        "layers.21.self_attn.o_proj.weight",
        "layers.21.self_attn.q_proj.weight",
        "layers.22.self_attn.q_proj.weight",
        "layers.23.self_attn.q_proj.weight",
        "layers.24.self_attn.o_proj.weight",
        "layers.24.self_attn.q_proj.weight",
        "layers.25.self_attn.q_proj.weight",
        "layers.26.self_attn.q_proj.weight",
        "layers.27.self_attn.q_proj.weight",
        "layers.28.self_attn.q_proj.weight",
        "layers.29.self_attn.q_proj.weight",
        "layers.3.mlp.gate_proj.weight",
        "layers.3.self_attn.o_proj.weight",
        "layers.3.self_attn.q_proj.weight",
        "layers.30.self_attn.q_proj.weight",
        "layers.31.self_attn.q_proj.weight",
        "layers.32.self_attn.q_proj.weight",
        "layers.33.self_attn.q_proj.weight",
        "layers.34.self_attn.q_proj.weight",
        "layers.35.self_attn.q_proj.weight",
        "layers.4.mlp.gate_proj.weight",
        "layers.4.self_attn.o_proj.weight",
        "layers.4.self_attn.q_proj.weight",
        "layers.5.mlp.gate_proj.weight",
        "layers.5.self_attn.o_proj.weight",
        "layers.5.self_attn.q_proj.weight",
        "layers.6.mlp.gate_proj.weight",
        "layers.6.self_attn.q_proj.weight",
        "layers.7.mlp.gate_proj.weight",
        "layers.7.self_attn.o_proj.weight",
        "layers.7.self_attn.q_proj.weight",
        "layers.8.self_attn.o_proj.weight",
        "layers.8.self_attn.q_proj.weight",
        "layers.9.mlp.gate_proj.weight",
        "layers.9.self_attn.o_proj.weight",
        "layers.9.self_attn.q_proj.weight"
      ]
    }
  },
  "transformer": {
    "weights_dtype": "uint4",
    "group_size": 32,
    "modules_to_not_convert": [
      "t_embedder", "cap_embedder", "siglip_embedder",
      "all_x_embedder", "all_final_layer", "adaLN_modulation",
      "attention.to_q", "attention.to_k", "attention.to_v", "attention.to_out"
    ],
    "modules_svd_dict": {
      "32": [
        "cap_embedder.1.weight",
        "context_refiner.0.attention.to_k.weight",
        "context_refiner.0.attention.to_out.0.weight",
        "context_refiner.0.attention.to_q.weight",
        "context_refiner.0.attention.to_v.weight",
        "context_refiner.0.feed_forward.w1.weight",
        "context_refiner.0.feed_forward.w2.weight",
        "context_refiner.0.feed_forward.w3.weight",
        "context_refiner.1.attention.to_k.weight",
        "context_refiner.1.attention.to_out.0.weight",
        "context_refiner.1.attention.to_q.weight",
        "context_refiner.1.attention.to_v.weight",
        "context_refiner.1.feed_forward.w1.weight",
        "context_refiner.1.feed_forward.w2.weight",
        "context_refiner.1.feed_forward.w3.weight",
        "layers.0.attention.to_k.weight",
        "layers.0.attention.to_q.weight",
        "layers.0.attention.to_v.weight",
        "layers.0.feed_forward.w1.weight",
        "layers.0.feed_forward.w2.weight",
        "layers.0.feed_forward.w3.weight",
        "layers.1.attention.to_k.weight",
        "layers.1.attention.to_q.weight",
        "layers.1.attention.to_v.weight",
        "layers.1.feed_forward.w1.weight",
        "layers.1.feed_forward.w2.weight",
        "layers.1.feed_forward.w3.weight",
        "layers.10.attention.to_k.weight",
        "layers.10.attention.to_out.0.weight",
        "layers.10.attention.to_q.weight",
        "layers.10.feed_forward.w2.weight",
        "layers.11.attention.to_k.weight",
        "layers.11.attention.to_out.0.weight",
        "layers.11.attention.to_q.weight",
        "layers.11.feed_forward.w2.weight",
        "layers.12.attention.to_k.weight",
        "layers.12.attention.to_out.0.weight",
        "layers.12.attention.to_q.weight",
        "layers.12.feed_forward.w2.weight",
        "layers.13.attention.to_k.weight",
        "layers.13.attention.to_out.0.weight",
        "layers.13.attention.to_q.weight",
        "layers.13.feed_forward.w2.weight",
        "layers.14.attention.to_k.weight",
        "layers.14.attention.to_out.0.weight",
        "layers.14.attention.to_q.weight",
        "layers.14.feed_forward.w2.weight",
        "layers.15.attention.to_k.weight",
        "layers.15.attention.to_out.0.weight",
        "layers.15.attention.to_q.weight",
        "layers.15.feed_forward.w2.weight",
        "layers.16.attention.to_k.weight",
        "layers.16.attention.to_out.0.weight",
        "layers.16.attention.to_q.weight",
        "layers.16.feed_forward.w2.weight",
        "layers.17.attention.to_k.weight",
        "layers.17.attention.to_out.0.weight",
        "layers.17.attention.to_q.weight",
        "layers.17.feed_forward.w2.weight",
        "layers.18.attention.to_k.weight",
        "layers.18.attention.to_out.0.weight",
        "layers.18.attention.to_q.weight",
        "layers.18.feed_forward.w2.weight",
        "layers.19.attention.to_k.weight",
        "layers.19.attention.to_out.0.weight",
        "layers.19.attention.to_q.weight",
        "layers.19.feed_forward.w2.weight",
        "layers.2.attention.to_k.weight",
        "layers.2.attention.to_q.weight",
        "layers.2.attention.to_v.weight",
        "layers.2.feed_forward.w1.weight",
        "layers.2.feed_forward.w2.weight",
        "layers.2.feed_forward.w3.weight",
        "layers.20.attention.to_k.weight",
        "layers.20.attention.to_out.0.weight",
        "layers.20.attention.to_q.weight",
        "layers.20.feed_forward.w2.weight",
        "layers.21.attention.to_k.weight",
        "layers.21.attention.to_out.0.weight",
        "layers.21.attention.to_q.weight",
        "layers.21.feed_forward.w2.weight",
        "layers.22.attention.to_k.weight",
        "layers.22.attention.to_out.0.weight",
        "layers.22.attention.to_q.weight",
        "layers.23.attention.to_k.weight",
        "layers.23.attention.to_out.0.weight",
        "layers.23.attention.to_q.weight",
        "layers.24.attention.to_k.weight",
        "layers.24.attention.to_out.0.weight",
        "layers.24.attention.to_q.weight",
        "layers.25.attention.to_k.weight",
        "layers.25.attention.to_out.0.weight",
        "layers.25.attention.to_q.weight",
        "layers.26.attention.to_k.weight",
        "layers.26.attention.to_out.0.weight",
        "layers.27.attention.to_k.weight",
        "layers.27.attention.to_out.0.weight",
        "layers.28.attention.to_out.0.weight",
        "layers.29.attention.to_out.0.weight",
        "layers.29.attention.to_q.weight",
        "layers.3.attention.to_k.weight",
        "layers.3.attention.to_out.0.weight",
        "layers.3.attention.to_q.weight",
        "layers.3.attention.to_v.weight",
        "layers.3.feed_forward.w1.weight",
        "layers.3.feed_forward.w2.weight",
        "layers.3.feed_forward.w3.weight",
        "layers.4.attention.to_k.weight",
        "layers.4.attention.to_out.0.weight",
        "layers.4.attention.to_q.weight",
        "layers.4.attention.to_v.weight",
        "layers.4.feed_forward.w1.weight",
        "layers.4.feed_forward.w2.weight",
        "layers.4.feed_forward.w3.weight",
        "layers.5.attention.to_k.weight",
        "layers.5.attention.to_out.0.weight",
        "layers.5.attention.to_q.weight",
        "layers.5.attention.to_v.weight",
        "layers.5.feed_forward.w1.weight",
        "layers.5.feed_forward.w2.weight",
        "layers.5.feed_forward.w3.weight",
        "layers.6.attention.to_k.weight",
        "layers.6.attention.to_out.0.weight",
        "layers.6.attention.to_q.weight",
        "layers.6.feed_forward.w1.weight",
        "layers.7.attention.to_k.weight",
        "layers.7.attention.to_out.0.weight",
        "layers.7.attention.to_q.weight",
        "layers.7.attention.to_v.weight",
        "layers.7.feed_forward.w1.weight",
        "layers.7.feed_forward.w2.weight",
        "layers.8.attention.to_k.weight",
        "layers.8.attention.to_out.0.weight",
        "layers.8.attention.to_q.weight",
        "layers.8.feed_forward.w2.weight",
        "layers.9.attention.to_k.weight",
        "layers.9.attention.to_out.0.weight",
        "layers.9.attention.to_q.weight",
        "layers.9.feed_forward.w1.weight",
        "layers.9.feed_forward.w2.weight",
        "noise_refiner.0.attention.to_k.weight",
        "noise_refiner.0.attention.to_out.0.weight",
        "noise_refiner.0.attention.to_q.weight",
        "noise_refiner.0.attention.to_v.weight",
        "noise_refiner.0.feed_forward.w1.weight",
        "noise_refiner.0.feed_forward.w2.weight",
        "noise_refiner.0.feed_forward.w3.weight",
        "noise_refiner.1.attention.to_k.weight",
        "noise_refiner.1.attention.to_out.0.weight",
        "noise_refiner.1.attention.to_q.weight",
        "noise_refiner.1.attention.to_v.weight",
        "noise_refiner.1.feed_forward.w1.weight",
        "noise_refiner.1.feed_forward.w2.weight",
        "noise_refiner.1.feed_forward.w3.weight"
      ],
      "64": [
        "layers.10.feed_forward.w1.weight",
        "layers.11.feed_forward.w1.weight",
        "layers.12.feed_forward.w1.weight",
        "layers.13.feed_forward.w1.weight",
        "layers.14.feed_forward.w1.weight",
        "layers.15.feed_forward.w1.weight",
        "layers.16.feed_forward.w1.weight",
        "layers.17.feed_forward.w1.weight",
        "layers.18.feed_forward.w1.weight",
        "layers.19.feed_forward.w1.weight",
        "layers.20.feed_forward.w1.weight",
        "layers.21.feed_forward.w1.weight",
        "layers.22.feed_forward.w2.weight",
        "layers.25.feed_forward.w1.weight",
        "layers.26.feed_forward.w1.weight",
        "layers.28.feed_forward.w2.weight",
        "layers.29.attention.to_k.weight",
        "layers.6.feed_forward.w2.weight",
        "layers.6.feed_forward.w3.weight",
        "layers.7.feed_forward.w3.weight",
        "layers.8.feed_forward.w1.weight",
        "layers.8.feed_forward.w3.weight"
      ],
      "96": [
        "layers.29.feed_forward.w2.weight"
      ]
    }
  }
}
